# python imports
import keras
import numpy as np
import tensorflow as tf
import keras.layers as KL
import keras.backend as K

# project imports
from . import utils
from .sample_gmm import sample_gmm_conditioned_on_labels
from .spatial_augmentation import deform_tensor, random_cropping
from .edit_tensors import convert_labels, reset_label_values_to_zero
from .edit_tensors import blur_channel, get_gaussian_1d_kernels, resample_tensor
from .intensity_augmentation import gamma_augmentation, bias_field_augmentation, min_max_normalisation


def lab2im_model(labels_shape,
                 n_channels,
                 generation_labels,
                 output_labels,
                 atlas_res,
                 target_res,
                 output_shape=None,
                 output_div_by_n=None,
                 blur_background=True,
                 blur_range=1.15):
    """
    This function builds a keras/tensorflow model to generate images from provided label maps.
    The images are generated by sampling a Gaussian Mixture Model (of given parameters), conditionned on the label map.
    The model will take as inputs:
        -a label map
        -a vector containing the means of the Gaussian Mixture Model for each label,
        -a vector containing the standard deviations of the Gaussian Mixture Model for each label,
        -an array of size batch*(n_dims+1)*(n_dims+1) representing a linear transformation
    The model returns:
        -the generated image normalised between 0 and 1.
        -the corresponding label map, with only the labels present in output_labels (the other are reset to zero).
    :param labels_shape: shape of the input label maps. Can be a sequence or a 1d numpy array.
    :param n_channels: number of channels to be synthetised.
    :param generation_labels: list of all possible label values in the input label maps.
    Can be a sequence or a 1d numpy array.
    :param output_labels: list of all the label values to keep in the output label maps.
    Should be a subset of the values contained in generation_labels.
    Label values that are in generation_labels but not in output_labels are reset to zero.
    Can be a sequence or a 1d numpy array. By default output_labels is equal to generation_labels.
    :param atlas_res: resolution of the input label maps.
    Can be a number (isotropic resolution), a sequence, or a 1d numpy array.
    :param target_res: target resolution of the generated images and corresponding label maps.
    Can be a number (isotropic resolution), a sequence, or a 1d numpy array.
    :param output_shape: (optional) desired shape of the output images.
    If the atlas and target resolutions are the same, the output will be cropped to output_shape, and if the two
    resolutions are different, the output will be resized with trilinear interpolation to output_shape.
    Can be an integer (same size in all dimensions), a sequence, or a 1d numpy array.
    :param output_div_by_n: (optional) forces the output shape to be divisible by this value. It overwrites output_shape
    if necessary. Can be an integer (same size in all dimensions), a sequence, or a 1d numpy array.
    :param blur_background: (optional) If True, the background is blurred with the other labels, and can be reset to
    zero with a probability of 0.2. If False, the background is not blurred (we apply an edge blurring correction), and
    can be replaced by a low-intensity background.
    :param blur_range: (optional) Randomise the standard deviation of the blurring kernels, (whether data_res is given
    or not). At each mini_batch, the standard deviation of the blurring kernels are multiplied by a coefficient sampled
    from a uniform distribution with bounds [1/blur_range, blur_range]. If None, no randomisation. Default is 1.15.
    """

    # reformat resolutions
    labels_shape = utils.reformat_to_list(labels_shape)
    n_dims, _ = utils.get_dims(labels_shape)
    atlas_res = utils.reformat_to_n_channels_array(atlas_res, n_dims=n_dims)[0]
    if target_res is None:
        target_res = atlas_res
    else:
        target_res = utils.reformat_to_n_channels_array(target_res, n_dims)[0]

    # get shapes
    crop_shape, output_shape = get_shapes(labels_shape, output_shape, atlas_res, target_res, output_div_by_n)

    # create new_label_list and corresponding LUT to make sure that labels go from 0 to N-1
    n_generation_labels = generation_labels.shape[0]
    new_generation_label_list, lut = utils.rearrange_label_list(generation_labels)

    # define model inputs
    labels_input = KL.Input(shape=labels_shape+[1], name='labels_input')
    means_input = KL.Input(shape=list(new_generation_label_list.shape) + [n_channels], name='means_input')
    std_devs_input = KL.Input(shape=list(new_generation_label_list.shape) + [n_channels], name='std_devs_input')
    aff_in = KL.Input(shape=(n_dims + 1, n_dims + 1), name='aff_input')
    list_inputs = [labels_input, means_input, std_devs_input, aff_in]

    # convert labels to new_label_list
    labels = convert_labels(labels_input, lut)

    # deform labels
    labels = deform_tensor(labels, affine_trans=aff_in, inter_method='nearest')
    labels = KL.Lambda(lambda x: tf.cast(x, dtype='int32'))(labels)

    # cropping
    if crop_shape != labels_shape:
        labels = random_cropping(labels, crop_shape, n_dims)

    # build synthetic image
    image = sample_gmm_conditioned_on_labels(labels, means_input, std_devs_input, n_generation_labels, n_channels)

    # loop over channels
    if n_channels > 1:
        split = KL.Lambda(lambda x: tf.split(x, [1] * n_channels, axis=-1))(image)
    else:
        split = [image]
    mask = KL.Lambda(lambda x: tf.where(tf.greater(x, 0), tf.ones_like(x, dtype='float32'),
                                        tf.zeros_like(x, dtype='float32')))(labels)
    processed_channels = list()
    for i, channel in enumerate(split):

        sigma = utils.get_std_blurring_mask_for_downsampling(target_res, atlas_res)
        kernels_list = get_gaussian_1d_kernels(sigma, blurring_range=blur_range)
        channel = blur_channel(channel, mask, kernels_list, n_dims, blur_background)

        # resample channel
        if crop_shape != output_shape:
            channel = resample_tensor(channel, output_shape, 'linear')

        # apply bias field
        channel = bias_field_augmentation(channel, bias_shape_factor=.025, bias_field_std=.3)

        # intensity augmentation
        channel = KL.Lambda(lambda x: K.clip(x, 0, 300))(channel)
        channel = min_max_normalisation(channel)
        processed_channels.append(gamma_augmentation(channel, std=0.2))

    # concatenate all channels back
    if n_channels > 1:
        image = KL.concatenate(processed_channels)
    else:
        image = processed_channels[0]

    # resample labels at target resolution
    if crop_shape != output_shape:
        labels = KL.Lambda(lambda x: tf.cast(x, dtype='float32'))(labels)
        labels = resample_tensor(labels, output_shape, interp_method='nearest')
    # convert labels back to original values and reset unwanted labels to zero
    labels = convert_labels(labels, generation_labels)
    labels_to_reset = [lab for lab in generation_labels if lab not in output_labels]
    labels = reset_label_values_to_zero(labels, labels_to_reset)
    labels = KL.Lambda(lambda x: tf.cast(x, dtype='int32'), name='labels_out')(labels)

    # build model (dummy layer enables to keep the labels when plugging this model to other models)
    image = KL.Lambda(lambda x: x[0], name='image_out')([image, labels])
    brain_model = keras.Model(inputs=list_inputs, outputs=[image, labels])

    return brain_model


def get_shapes(labels_shape, output_shape, atlas_res, target_res, output_div_by_n):

    n_dims = len(atlas_res)

    # get resampling factor
    if atlas_res.tolist() != target_res.tolist():
        resample_factor = [atlas_res[i] / float(target_res[i]) for i in range(n_dims)]
    else:
        resample_factor = None

    # output shape specified, need to get cropping shape, and resample shape if necessary
    if output_shape is not None:
        output_shape = utils.reformat_to_list(output_shape, length=n_dims, dtype='int')

        # make sure that output shape is smaller or equal to label shape
        if resample_factor is not None:
            output_shape = [min(int(labels_shape[i] * resample_factor[i]), output_shape[i]) for i in range(n_dims)]
        else:
            output_shape = [min(labels_shape[i], output_shape[i]) for i in range(n_dims)]

        # make sure output shape is divisible by output_div_by_n
        if output_div_by_n is not None:
            tmp_shape = [utils.find_closest_number_divisible_by_m(s, output_div_by_n, smaller_ans=True)
                         for s in output_shape]
            if output_shape != tmp_shape:
                print('output shape {0} not divisible by {1}, changed to {2}'.format(output_shape, output_div_by_n,
                                                                                     tmp_shape))
                output_shape = tmp_shape

        # get cropping and resample shape
        if resample_factor is not None:
            cropping_shape = [int(np.around(output_shape[i]/resample_factor[i], 0)) for i in range(n_dims)]
        else:
            cropping_shape = output_shape

    # no output shape specified, so no cropping unless label_shape is not divisible by output_div_by_n
    else:
        cropping_shape = labels_shape
        if resample_factor is not None:
            output_shape = [int(np.around(cropping_shape[i]*resample_factor[i], 0)) for i in range(n_dims)]
        else:
            output_shape = cropping_shape
        # make sure output shape is divisible by output_div_by_n
        if output_div_by_n is not None:
            output_shape = [utils.find_closest_number_divisible_by_m(s, output_div_by_n, smaller_ans=False)
                            for s in output_shape]

    return cropping_shape, output_shape
